{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import geopandas as gpd \n",
    "import folium \n",
    "import datetime\n",
    "import json\n",
    "import branca\n",
    "import statistics\n",
    "import random as rd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#récupère la liste des stops points doublons, modification de leur access par la moyenne de leur accessbilité  avec ajout d'une nouvelle colonne 'new_access'\n",
    "def access_doublons(str_chemin_csv):\n",
    "    list_index_doublons = []\n",
    "    df = pd.read_csv(str_chemin_csv, sep=\";\")\n",
    "\n",
    "    for k in range(len(df)):\n",
    "        if len(df[df['Coord'] == df.loc[k]['Coord']])>1:\n",
    "            index = df[df['Coord'] == df.loc[k]['Coord']].index.values\n",
    "            tmp = [index[j] for j in range(len(index))]\n",
    "            if tmp not in list_index_doublons :\n",
    "                list_index_doublons.append(tmp) \n",
    "    list_idx = []\n",
    "    for j in range(len(list_index_doublons)) :\n",
    "        list_idx.append(list_index_doublons[j][0])\n",
    "        list_idx.append(list_index_doublons[j][1])\n",
    "\n",
    "    list_new_access = [0.0]*len(df)\n",
    "    idx = 0\n",
    "    for k in range(len(df)):\n",
    "        if k in list_idx :\n",
    "            l = len(df[df['Coord'] == df.loc[k]['Coord']])\n",
    "            s = np.sum(list(df.loc[list_index_doublons[idx]]['Access']))\n",
    "            m = np.round(s/l,2)\n",
    "            list_new_access[list_index_doublons[idx][0]] = m \n",
    "            list_new_access[list_index_doublons[idx][1]] = m\n",
    "            for ele in range(l):\n",
    "                list_idx.remove(list_index_doublons[idx][ele])\n",
    "            idx+= 1\n",
    "        elif list_new_access[k] == 0.0 : \n",
    "            list_new_access[k] = df.loc[k]['Access']\n",
    "\n",
    "    df['new_access']=list_new_access\n",
    "    #print(list_index_doublons)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Création des df, attention les df avce 150 et 200 points sont calculés avec 5 ss processus et non 10 donc data ordonnées différement \n",
    "\n",
    "data_stop_0930_25 = access_doublons('./25points/csv/merged_1000SP_09h30_25points.csv')\n",
    "data_stop_0930_50 = access_doublons('./50points/csv/merged_1000SP_09h30_50points.csv') \n",
    "data_stop_0930_100 = access_doublons('./100points/csv/merged1000SP_09h30_100points.csv') \n",
    "data_stop_0930_150 = access_doublons('./150points/csv/merged1000SP_09h30_150points.csv')\n",
    "data_stop_0930_200 = access_doublons('./200points/csv/merged1000SP_09h30_200points.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## on va donc réorganiser les df 150 et 200\n",
    "\n",
    "def reorder_df(df): #reorder par rapport à data_stop_0930_100\n",
    "    list_data = []\n",
    "\n",
    "    for k in range(len(df)):\n",
    "        data = df[(df['Coord']==data_stop_0930_100.loc[k]['Coord'])]\n",
    "        if len(df[(df['Coord']==data_stop_0930_100.loc[k]['Coord'])])<=1:\n",
    "            list_data.append(data)\n",
    "        else : #lorsqu'il y a un doublon on ne peut les réordonner d'une manière certaine donc on prend la première ligne trouvée pas d'importance sur new_access\n",
    "            data_doublon = df[(df['Coord']==data_stop_0930_100.loc[k]['Coord'])][:1]\n",
    "            list_data.append(data_doublon)\n",
    "    df_reorder = pd.concat(list_data)\n",
    "    return df_reorder\n",
    "\n",
    "data_stop_0930_150 = reorder_df(data_stop_0930_150)\n",
    "data_stop_0930_200 = reorder_df(data_stop_0930_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversion_temps_unique(d):\n",
    "    hours = int(d//3600)  \n",
    "    if 10>hours>=0 :\n",
    "        min = int(np.round(d%3600//60))\n",
    "        sec = int(np.round(d%3600%60))\n",
    "        if min<10 and sec<10:\n",
    "            return '0'+str(hours)+':0'+str(min)+':0'+str(sec)\n",
    "        elif min>=10 and sec>=10:\n",
    "            return '0'+str(hours)+':'+str(min)+':'+str(sec)\n",
    "        elif min>=10 and sec<10 :\n",
    "            return '0'+str(hours)+':'+str(min)+':0'+str(sec)\n",
    "        else :\n",
    "            return '0'+str(hours)+':0'+str(min)+':'+str(sec)\n",
    "    return '>=10h'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conversion_temps_access(df):\n",
    "    list_access_s = list(df['new_access'])\n",
    "    list_access,list_access_min = [], []\n",
    "    s1,s10 = 0,0\n",
    "    for k in range(len(list_access_s)):\n",
    "        list_access_min.append(np.round(list_access_s[k]/60,2))\n",
    "        hours = int(list_access_s[k]//3600)\n",
    "        if 10>hours>=0 :\n",
    "            if hours >1 :\n",
    "                #print(k,'... grande accessibilité')\n",
    "                s1+=1\n",
    "            min = int(np.round(list_access_s[k]%3600//60))\n",
    "            sec = int(np.round(list_access_s[k]%3600%60))\n",
    "            if min<10 and sec<10:\n",
    "                list_access.append('0'+str(hours)+':0'+str(min)+':0'+str(sec))\n",
    "            elif min>=10 and sec>=10:\n",
    "                list_access.append('0'+str(hours)+':'+str(min)+':'+str(sec))\n",
    "            elif min>=10 and sec<10 :\n",
    "                list_access.append('0'+str(hours)+':'+str(min)+':0'+str(sec))\n",
    "            else :\n",
    "                list_access.append('0'+str(hours)+':0'+str(min)+':'+str(sec))\n",
    "        elif hours>=10 :\n",
    "            #print(k,'... grande accessibilité')\n",
    "            s10+=1\n",
    "            min = int(np.round(list_access_s[k]%3600//60))\n",
    "            sec = int(np.round(list_access_s[k]%3600%60))\n",
    "            if min<10 and sec<10:\n",
    "                list_access.append(str(hours)+':0'+str(min)+':0'+str(sec))\n",
    "            elif min>=10 and sec>=10:\n",
    "                list_access.append(str(hours)+':'+str(min)+':'+str(sec))\n",
    "            elif min>=10 and sec<10 :\n",
    "                list_access.append(str(hours)+':'+str(min)+':0'+str(sec))\n",
    "            else :\n",
    "                list_access.append(str(hours)+':0'+str(min)+':'+str(sec))\n",
    "        else : \n",
    "            list_access.append('00:00:00')\n",
    "    print(s1, ' SP ont une access > 1h')\n",
    "    print(s10, ' SP ont une access >= 10h')\n",
    "    df['access_min'] = list_access_min\n",
    "    df['access_h_m_s']= list_access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord_gps(df):\n",
    "\n",
    "    Coord_gps_list, Latitude_list, Longitude_list = [], [], []\n",
    "\n",
    "    for coord in list(df['Coord']):\n",
    "        index = coord.find(',')\n",
    "        lat = coord[:index]\n",
    "        lon = coord[index+1:]\n",
    "        Longitude_list.append(float(lon))\n",
    "        Latitude_list.append(float(lat))\n",
    "        Coord_gps_list.append([lat,lon])\n",
    "\n",
    "    df['Coord_gps'] = Coord_gps_list\n",
    "    df['Longitude'] = Longitude_list\n",
    "    df['Latitude'] = Latitude_list\n",
    "\n",
    "coord_gps(data_stop_0930_25)\n",
    "coord_gps(data_stop_0930_50)\n",
    "coord_gps(data_stop_0930_100)\n",
    "coord_gps(data_stop_0930_150)\n",
    "coord_gps(data_stop_0930_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_0930 = [data_stop_0930_25,data_stop_0930_50,data_stop_0930_100,data_stop_0930_150,data_stop_0930_200]\n",
    "data_comparaison_0930 = pd.concat(list_df_0930)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "638  SP ont une access > 1h\n0  SP ont une access >= 10h\n"
     ]
    }
   ],
   "source": [
    "conversion_temps_access(data_comparaison_0930)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#création CSV modifiés\n",
    "data_comparaison_0930.to_csv('./stops_concat_1000SP_0930.csv', sep = ';',index=False) \n",
    "\n",
    "data_stop_0930_25.to_csv('./25points/csv/1000SP_09h30_25points.csv', sep = ';',index=False)\n",
    "data_stop_0930_50.to_csv('./50points/csv/1000SP_09h30_50points.csv', sep = ';',index=False)\n",
    "data_stop_0930_100.to_csv('./100points/csv/1000SP_09h30_100points.csv', sep = ';',index=False)\n",
    "data_stop_0930_150.to_csv('./150points/csv/1000SP_09h30_150points.csv', sep = ';',index=False)\n",
    "data_stop_0930_200.to_csv('./200points/csv/1000SP_09h30_200points.csv', sep = ';',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "87  SP ont une access > 1h\n",
      "0  SP ont une access >= 10h\n",
      "191  SP ont une access > 1h\n",
      "0  SP ont une access >= 10h\n",
      "125  SP ont une access > 1h\n",
      "0  SP ont une access >= 10h\n",
      "132  SP ont une access > 1h\n",
      "0  SP ont une access >= 10h\n",
      "120  SP ont une access > 1h\n",
      "0  SP ont une access >= 10h\n"
     ]
    }
   ],
   "source": [
    "data_stop_0830 = access_doublons('./100points/csv/merged1000SP_08h30_100points.csv')\n",
    "data_stop_09 = access_doublons('./100points/csv/merged1000SP_09h00_100points.csv') \n",
    "data_stop_0930 = access_doublons('./100points/csv/merged1000SP_09h30_100points.csv')\n",
    "data_stop_10 = access_doublons('./100points/csv/merged1000SP_10h00_100points.csv') \n",
    "data_stop_1030 = access_doublons('./100points/csv/merged1000SP_10h30_100points.csv')\n",
    "\n",
    "#\n",
    "coord_gps(data_stop_0830)\n",
    "coord_gps(data_stop_09)\n",
    "coord_gps(data_stop_0930)\n",
    "coord_gps(data_stop_10)\n",
    "coord_gps(data_stop_1030)\n",
    "\n",
    "conversion_temps_access(data_stop_0830)\n",
    "conversion_temps_access(data_stop_09)\n",
    "conversion_temps_access(data_stop_0930)\n",
    "conversion_temps_access(data_stop_10)\n",
    "conversion_temps_access(data_stop_1030)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  Name               Coord    Access              time  \\\n",
       "0          Jean Jaurès  48.974702,1.803076   6420.16  03-08-2021 08:30   \n",
       "1   GARE DE ST GRATIEN  48.964243,2.285417   3521.32  03-08-2021 08:30   \n",
       "2     Pierre Stassinet   48.78268,1.959276   6981.49  03-08-2021 08:30   \n",
       "3   Quartier de Lattre  48.533199,3.372171      0.00  03-08-2021 08:30   \n",
       "4  Croix de Vernailles   48.44603,2.166975  11716.80  03-08-2021 08:30   \n",
       "\n",
       "   new_access              Coord_gps  Longitude   Latitude  access_min  \\\n",
       "0     6420.16  [48.974702, 1.803076]   1.803076  48.974702      107.00   \n",
       "1     3521.32  [48.964243, 2.285417]   2.285417  48.964243       58.69   \n",
       "2     6981.49   [48.78268, 1.959276]   1.959276  48.782680      116.36   \n",
       "3        0.00  [48.533199, 3.372171]   3.372171  48.533199        0.00   \n",
       "4    11716.80   [48.44603, 2.166975]   2.166975  48.446030      195.28   \n",
       "\n",
       "  access_h_m_s  \n",
       "0     01:47:00  \n",
       "1     00:58:41  \n",
       "2     01:56:21  \n",
       "3     00:00:00  \n",
       "4     03:15:17  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Coord</th>\n      <th>Access</th>\n      <th>time</th>\n      <th>new_access</th>\n      <th>Coord_gps</th>\n      <th>Longitude</th>\n      <th>Latitude</th>\n      <th>access_min</th>\n      <th>access_h_m_s</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Jean Jaurès</td>\n      <td>48.974702,1.803076</td>\n      <td>6420.16</td>\n      <td>03-08-2021 08:30</td>\n      <td>6420.16</td>\n      <td>[48.974702, 1.803076]</td>\n      <td>1.803076</td>\n      <td>48.974702</td>\n      <td>107.00</td>\n      <td>01:47:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GARE DE ST GRATIEN</td>\n      <td>48.964243,2.285417</td>\n      <td>3521.32</td>\n      <td>03-08-2021 08:30</td>\n      <td>3521.32</td>\n      <td>[48.964243, 2.285417]</td>\n      <td>2.285417</td>\n      <td>48.964243</td>\n      <td>58.69</td>\n      <td>00:58:41</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Pierre Stassinet</td>\n      <td>48.78268,1.959276</td>\n      <td>6981.49</td>\n      <td>03-08-2021 08:30</td>\n      <td>6981.49</td>\n      <td>[48.78268, 1.959276]</td>\n      <td>1.959276</td>\n      <td>48.782680</td>\n      <td>116.36</td>\n      <td>01:56:21</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Quartier de Lattre</td>\n      <td>48.533199,3.372171</td>\n      <td>0.00</td>\n      <td>03-08-2021 08:30</td>\n      <td>0.00</td>\n      <td>[48.533199, 3.372171]</td>\n      <td>3.372171</td>\n      <td>48.533199</td>\n      <td>0.00</td>\n      <td>00:00:00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Croix de Vernailles</td>\n      <td>48.44603,2.166975</td>\n      <td>11716.80</td>\n      <td>03-08-2021 08:30</td>\n      <td>11716.80</td>\n      <td>[48.44603, 2.166975]</td>\n      <td>2.166975</td>\n      <td>48.446030</td>\n      <td>195.28</td>\n      <td>03:15:17</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "data_stop_0830.head()"
   ]
  },
  {
   "source": [
    "def postcode_dep(df):\n",
    "\n",
    "    list_postcode = []\n",
    "    list_dep = []\n",
    "\n",
    "    for k in range(len(df)):\n",
    "        res = requests.get('https://api-adresse.data.gouv.fr/reverse/?lon='+list(df['Coord_gps'])[k][1]+'&lat='+list(df['Coord_gps'])[k][0])\n",
    "        data = res.json()\n",
    "        if len(data['features'])!=0:\n",
    "            postcode = data['features'][0]['properties']['postcode'][:2]\n",
    "            list_postcode.append(postcode)\n",
    "            if postcode=='75' :\n",
    "                list_dep.append('Paris')\n",
    "            elif postcode=='77' :\n",
    "                list_dep.append('Seine-et-Marne')\n",
    "            elif postcode=='78' :\n",
    "                list_dep.append('Yvelines')\n",
    "            elif postcode=='91' :\n",
    "                list_dep.append('Essonne')\n",
    "            elif postcode=='92' :\n",
    "                list_dep.append('Hauts-de-Seine')\n",
    "            elif postcode=='93' :\n",
    "                list_dep.append('Seine-Saint-Denis')\n",
    "            elif postcode=='94' :\n",
    "                list_dep.append('Val-de-Marne')\n",
    "            elif postcode=='95' :\n",
    "                list_dep.append('Val-d\\'Oise')\n",
    "            else : \n",
    "                print(postcode,' : postcode pas en Ile de France')\n",
    "                list_dep.append('Erreur postcode pas en Ile de France')\n",
    "        else : \n",
    "            print('Erreur API, postcode non disponible')\n",
    "            list_postcode.append(0)\n",
    "            list_dep.append('Erreur API')\n",
    "\n",
    "    df['postcode']=list_postcode\n",
    "    df['dep']=list_dep\n",
    "\n",
    "postcode_dep(data_stop_0830) #pour diminuer grandement le temps on peut simplement le faire sur un df puis recopier les colonnes dep et postcode dans les autres df car même ordre...\n",
    "postcode_dep(data_stop_09)\n",
    "postcode_dep(data_stop_0930)\n",
    "postcode_dep(data_stop_10)\n",
    "postcode_dep(data_stop_1030)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "27  : postcode pas en Ile de France\n",
      "Erreur API, postcode non disponible\n",
      "Erreur API, postcode non disponible\n",
      "28  : postcode pas en Ile de France\n",
      "28  : postcode pas en Ile de France\n",
      "45  : postcode pas en Ile de France\n",
      "27  : postcode pas en Ile de France\n",
      "Erreur API, postcode non disponible\n",
      "Erreur API, postcode non disponible\n",
      "28  : postcode pas en Ile de France\n",
      "28  : postcode pas en Ile de France\n",
      "45  : postcode pas en Ile de France\n",
      "27  : postcode pas en Ile de France\n",
      "Erreur API, postcode non disponible\n",
      "Erreur API, postcode non disponible\n",
      "28  : postcode pas en Ile de France\n",
      "28  : postcode pas en Ile de France\n",
      "45  : postcode pas en Ile de France\n",
      "27  : postcode pas en Ile de France\n",
      "Erreur API, postcode non disponible\n",
      "Erreur API, postcode non disponible\n",
      "28  : postcode pas en Ile de France\n",
      "28  : postcode pas en Ile de France\n",
      "45  : postcode pas en Ile de France\n",
      "27  : postcode pas en Ile de France\n",
      "Erreur API, postcode non disponible\n",
      "Erreur API, postcode non disponible\n",
      "28  : postcode pas en Ile de France\n",
      "28  : postcode pas en Ile de France\n",
      "45  : postcode pas en Ile de France\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data = [data_stop_0830,data_stop_09,data_stop_0930,data_stop_10,data_stop_1030]\n",
    "data_concat_0830_1030 = pd.concat(list_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_time_min=[]\n",
    "\n",
    "for k in range(len(data_concat_0830_1030)):\n",
    "    if list(data_concat_0830_1030['time'])[k]=='03-08-2021 08:30':\n",
    "        list_time_min.append(510)\n",
    "    elif list(data_concat_0830_1030['time'])[k]=='03-08-2021 09:00':\n",
    "        list_time_min.append(540)\n",
    "    elif list(data_concat_0830_1030['time'])[k]=='03-08-2021 09:30':\n",
    "        list_time_min.append(570)\n",
    "    elif list(data_concat_0830_1030['time'])[k]=='03-08-2021 10:00':\n",
    "        list_time_min.append(600)\n",
    "    elif list(data_concat_0830_1030['time'])[k]=='03-08-2021 10:30':\n",
    "        list_time_min.append(630)\n",
    "        \n",
    "data_concat_0830_1030['time_min'] = list_time_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_concat_0830_1030[data_concat_0830_1030['dep']=='Erreur postcode pas en Ile de France']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "655  SP ont une access > 1h\n0  SP ont une access >= 10h\n"
     ]
    }
   ],
   "source": [
    "conversion_temps_access(data_concat_0830_1030)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Counter({'Yvelines': 708,\n",
       "         'Essonne': 590,\n",
       "         'Seine-et-Marne': 499,\n",
       "         'Seine-Saint-Denis': 297,\n",
       "         'Hauts-de-Seine': 324,\n",
       "         \"Val-d'Oise\": 424,\n",
       "         'Val-de-Marne': 240,\n",
       "         'Paris': 163,\n",
       "         'Erreur API': 10})"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(list(data_concat_0830_1030[data_concat_0830_1030['access_h_m_s']>'01:00:00']['dep']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_var = [0]*1000\n",
    "\n",
    "for k in range(1000):\n",
    "    liste_var[k] = statistics.pstdev(data_concat_0830_1030[data_concat_0830_1030['Name'] == list(data_concat_0830_1030['Name'])[k]]['Access'])\n",
    "\n",
    "data_concat_0830_1030['Variance_access'] = liste_var*5 #à vérifier doublons, même nom et diff coord gps.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#création CSV modifiés\n",
    "\n",
    "data_stop_0830.to_csv('/home/thd/idf-accessibility/ponctuel/100/csv/1000SP_0830.csv', sep = ';',index=False)\n",
    "data_stop_09.to_csv('/home/thd/idf-accessibility/ponctuel/100/csv/1000SP_09.csv', sep = ';',index=False)\n",
    "data_stop_0930.to_csv('/home/thd/idf-accessibility/ponctuel/100/csv/1000SP_0930.csv', sep = ';',index=False)\n",
    "data_stop_10.to_csv('/home/thd/idf-accessibility/ponctuel/100/csv/1000SP_10.csv', sep = ';',index=False)\n",
    "data_stop_1030.to_csv('/home/thd/idf-accessibility/ponctuel/100/csv/1000SP_1030.csv', sep = ';',index=False)\n",
    "data_concat_0830_1030.to_csv('/home/thd/idf-accessibility/ponctuel/100/csv/stops_concat_1000SP_0830_1030.csv', sep = ';',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}